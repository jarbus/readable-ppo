# readable ppo

An arguably-readable implementation of PPO, from Schulman et al's 2017 paper, [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347).

# Usage

The following two lines will run the included PPO algorithm on the bundled CartPole environment

```julia
julia> include("PPO.jl")
julia> PPO()
```
